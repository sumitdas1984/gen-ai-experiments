{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "## load the GROQ And OpenAI API KEY \n",
    "groq_api_key=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 documents\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(\"./documents\")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 58 chunks\n"
     ]
    }
   ],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200) ## Chunk Creation\n",
    "final_documents=text_splitter.split_documents(docs) #splitting\n",
    "print(f\"Split into {len(final_documents)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'} # Use 'cuda' if you have a GPU\n",
    "    )\n",
    "vectors=FAISS.from_documents(final_documents, embeddings) #vector OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions based on the provided context.\"\n",
    "              \"If you don't know the answer, say 'I don't know'.\\n\\n\"\n",
    "              \"Context:\\n{context}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain=create_stuff_documents_chain(llm, prompt)\n",
    "retriever=vectors.as_retriever(search_kwargs={\"k\": 5})\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Answer ---\n",
      "According to the context, the penalty rule was developed in relation to the specific situation of enforcement of penal bonds, and its application was later extended to other contracts. The content of the penalty rule is not explicitly stated, but it is mentioned that it requires a breach of contract for the clause to be enforceable. Additionally, it is mentioned that the penalty rule is confined to the sphere of secondary obligations, without interfering with the primary obligations between the contracting parties.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is the content of the penalty rule?\"\n",
    "response=retrieval_chain.invoke({'input':user_question})\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
